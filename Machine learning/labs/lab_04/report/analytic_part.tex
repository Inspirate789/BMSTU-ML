\chapter{Аналитическая часть}



\section{Корреляция}

Корреляция (от лат. correlatio «соотношение, взаимосвязь»), или
корреляционная зависимость — статистическая взаимосвязь двух или
более случайных величин (либо величин, которые можно с некоторой
допустимой степенью точности считать таковыми). При этом изменения
значений одной или нескольких из этих величин сопутствуют
систематическому изменению значений другой или других величин.

Значительная корреляция между двумя случайными величинами
всегда является свидетельством существования некоторой
статистической связи в данной выборке, но эта связь не обязательно
должна наблюдаться для другой выборки и иметь причинно-
следственный характер.
\begin{itemize}[label*=---]
\item Рассматривая пожары в конкретном городе, можно выявить весьма
высокую корреляцию между ущербом, который нанёс пожар, и
количеством пожарных, участвовавших в ликвидации пожара,
причём эта корреляция будет положительной.
\item Из этого не следует вывод «увеличение количества пожарных
приводит к увеличению причинённого ущерба», и тем более не будет
успешной попытка минимизировать ущерб от пожаров путём
ликвидации пожарных бригад.
Отсутствие корреляции между двумя величинами ещё не значит,
что между ними нет никакой связи. Например, зависимость может
иметь сложный нелинейный характер, который корреляция не
выявляет.
\end{itemize}

Некоторые виды коэффициентов корреляции могут быть
положительными или отрицательными. В первом случае предполагается, что мы можем определить
только наличие или отсутствие связи, а во втором — также и её
направление.

Если предполагается, что на значениях переменных задано
отношение строгого порядка, то в этом случае:
\begin{itemize}[label*=---]
	\item Отрицательная корреляция — корреляция, при которой
	увеличение одной переменной связано с уменьшением другой.
	\item Положительная корреляция в таких условиях — это такая связь,
	при которой увеличение одной переменной связано с
	увеличением другой переменной.
\end{itemize}

Возможна также ситуация отсутствия статистической
взаимосвязи — например, для независимых случайных
величин.

Ограничения корреляционного анализа:
\begin{itemize}[label*=---]
	\item Применение возможно при наличии достаточного количества наблюдений для
	изучения.
	\item Коэффициент корреляции отражает «зашумлённость» линейной зависимости
	(верхняя строка)
	\item Коэффициент корреляции не описывает наклон линейной зависимости
	(средняя строка)
	\item Коэффициент корреляции совсем не подходит для описания сложных,
	нелинейных зависимостей (нижняя строка).
	\item Для распределения, показанного в центре рисунка, коэффициент корреляции не
	определен, так как дисперсия y равна нулю.
\end{itemize}


\section{Регрессионный анализ}

Набор методов моделирования измеряемых данных и исследования
их свойств, относится к разделам математической статистики и
машинного обучения. Осуществляет исследование влияния одной или
нескольких независимых переменных $X_1, X_2, …, X_p$ на зависимую
переменную $Y$.

Независимые переменные называют регрессорами, предикторами
или объясняющими переменными, а зависимая переменная является
результирующей, критериальной или регрессантом. Терминология
зависимых и независимых переменных отражает лишь
математическую зависимость переменных, а не причинно-
следственные отношения.

Наиболее распространенный вид регрессионного анализа —
линейная регрессия, когда находят линейную функцию, которая, согласно
определённым математическим критериям, наилучшим образом
соответствует данным.

Регрессионный анализ очень тесно связан с корреляционным
анализом. В корреляционном анализе исследуется направление и
теснота связи между количественными переменными. В регрессионном
анализе исследуется форма зависимости между количественными
переменными.

Регрессионный анализ используется для прогноза, анализа
временных рядов, тестирования гипотез и выявления скрытых
взаимосвязей в данных.



\clearpage

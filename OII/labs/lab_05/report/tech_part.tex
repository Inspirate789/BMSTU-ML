\chapter{Генерация текстов при помощи предобученных моделей}

Для генерации текстов были взяты предобученные модели qwen2.5~\cite{qwen} с тегами 0.5b, 7b и 14b, означающими число параметров модели. Для оценки <<человечности>> текстов, сгенерированных моделями, была взята затравочная фраза с нестрогим порядком слов: <<Кошка съела мышку? Или мышку съела кошка? А может кошка мышку съела? Или всё-таки съела кошка мышку?>>. Тексты, сгенерированные рассматриваемыми моделями, представлены на листингах \ref{lst:3}-\ref{lst:5}.

\begin{lstlisting}[label=lst:3,caption=Текст\, сгенерированный моделью qwen2.5:0.5b]
	@Что бы вы хотели сказать, это решает 2 вещи: @

	@1. Мыши могут съесть кошек или кошек тоже могут съесть мышей.@
	@2. С другой стороны, кошки не могут съесть мышиного животного.@
	
	@Эти два вопроса имеют одинаковую ответную форму - "или всё-таки съела кошка мышку?@
	@Или кошка мышка съела кошки?" @
	
	@Но, к сожалению, даже с учетом этих обстоятельств, можно сказать следующее: @
	
	@1. Мыши могут съесть кошек.@
	@2. Кошки могут съесть мышиного животного.@
	
	@Изначально эта ситуация может показаться непонятной, но в реальности она@
	@действительно существует и работает.@
	
	@Однако, давайте попробуем разобрать её более подробно:@
	
	@1. **Мыши могут съесть кошек**:@
	@- Кошки — это животные, которые обычно не съедают людей.@
	@- Мышки — это животные, которые часто пишут и часто едят мускулатуру.@
	
	@2. **Кошки могут съесть мышиного животного**:@
	@- Мускулатура — это съедобная часть человека, включая кожу, ртушину, желтый@
	@  оттенок кожи и даже мочи.@
	@- Мыши — это животные, которые часто пишут, что указывает на то, что они также @
	@  могут съесть мускулатуру.@
	@- Мыши — это животные, которые обычно не едят людей.@
	
	@3. **С другой стороны, кошки не могут съесть мышиного животного**:@
	@- Кошки — это животные, которые часто пишут и ездят в поездке.@
	
	@Таким образом, в целом ситуация может показаться непонятной из-за того, что мыши@
	@могут съесть кошек, но кошки не могут съесть мускулатуру.@
\end{lstlisting}

\begin{lstlisting}[label=lst:4,caption=Текст\, сгенерированный моделью qwen2.5:7b]
@Правильный порядок слов в последнем варианте будет: "Кошка съела мышку". @
@Это предложение грамматически правильное и ясно передает действие. @
@В других вариантах порядок слов не соответствует русской грамматике:@

@1. "Кошка съела мышку?" - это вопрос, который можно использовать для проверки понимания.@
@2. "Мышку съела кошка?" - тоже вопрос, но менее естественный, чем первый вариант.@
@3. "Кошка мышку съела" - грамматически некорректно, так как местоимение должно стоять@
@    после глагола.@

@Таким образом, правильный ответ: кошка съела мышку.@
\end{lstlisting}

\begin{lstlisting}[label=lst:5,caption=Текст\, сгенерированный моделью qwen2.5:14b]
@Все эти варианты передают одну и ту же идею, но наиболее правильным и @
@распространённым в русском языке будет вариант: "Кошка съела мышку." Однако,@
@варианты  "Мышку съела кошка" и "Кошка мышку съела" тоже корректны, просто они@
@менее естественны для употребления. Важно отметить, что порядок слов в русском языке@
@может меняться для акцентирования внимания на определённые части предложения или@
@по стилистическим соображениям, но смысл при этом остаётся неизменным.@
\end{lstlisting}

По мнению экспертов, текст, сгенерированный первой моделью, нельзя считать <<человечными>> как минимум потому, что сгенерированный текст даёт неестественный ответ на поставленный вопрос. Во втором тексте была замечена оценка естественности подвопросов исходного вопроса, но в данном тексте также присутствует ошибка разбора грамматики исходного вопроса. Третий текст содержит разбор исходного запроса, а также, по мнению экспертов, может считаться <<человечным>>.

Также стоит отметить, что во всех сгенерированных текстах прослеживается строгий порядок слов SVO. Исходя из этого, можно сделать предположение о том, что обучающая выборка для модели qwen имела строгий базовый порядок слов в предложениях, а именно SVO.

\section*{Вывод}

В данном разделе была рассмотрена генерация текстов при помощи различных версий предобученной модели qwen. На основе сгенерированных текстов можно сделать вывод о том, что между <<человечностью>> текстов и числом параметров генерирующей модели существует прямая зависимость.

\clearpage

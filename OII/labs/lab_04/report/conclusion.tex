\ssr{ЗАКЛЮЧЕНИЕ}

В рамках лабораторной работы была проведена классификация данных из датасета MNIST с использованием нейросетевого подхода с заданными функциями активации и потерь (ReLU и Cross-Entropy соответственно). Все поставленные задачи были выполнены.

\begin{enumerate}[label*=\arabic*)]
	\item Определены состояния переобучения и недообучения для различного соотношения обучающей и тестовой выборок.
	\item Определены состояния переобучения и недообучения для различного количества скрытых слоёв нейронной сети.
	\item Рассчитан аналитически необходимый размер обучающей выборки по неравенству Чебышёва, необходимый для гарантированного успешного выполнения поставленной задачи.
\end{enumerate}

Точность модели зависит от соотношения обучающих и тестовых выборок. Оптимальное соотношение составляет 90\% обучающих данных и 10\% тестовых. Именно при таком соотношении и при использовании одного скрытого слоя достигается наивысшая точность обучения (98.6\%) и тестирования (97.6\%).

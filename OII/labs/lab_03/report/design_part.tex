\chapter{Конструкторская часть}

\section{Генетический алгоритм}

Генетический алгоритм начинается с популяции случайно выбранных потенциальных решений (индивидуумов), для которых вычисляется функция приспособленности. Алгоритм выполняет цикл, в котором последовательно применяются операторы отбора, скрещивания и мутации, после чего приспособленность индивидуумов пересчитывается. Цикл продолжается, пока не выполнено условие остановки, после чего лучший индивидуум в текущей популяции считается решением.~\cite{book1}

Начальная популяция состоит из случайным образом выбранных потенциальных решений (индивидуумов). Поскольку в генетических алгоритмах индивидуумы представлены хромосомами, начальная популяция – это, по сути дела, набор хромосом. Формат хромосом должен соответствовать принятым для решаемой задачи правилам, например это могут быть двоичные строки определённой длины.~\cite{book1} В случае аппроксимации функций хромосомой будет являться значение схожести аппроксимированного и истинного значения функции в точке. Данное значение предлагается рассчитывать по формуле

\label{fitness}
\begin{equation}
	fitness = \frac{1}{\sigma^2},
\end{equation}
где $\sigma$ - среднеквадратичное отклонение между аппроксимируемой и
аппроксимирующей функциями.

Для каждого индивидуума вычисляется функция приспособленности. Это делается один раз для начальной популяции, а затем для каждого нового поколения после применения операторов отбора, скрещивания и мутации. Поскольку приспособленность любого индивидуума не зависит от всех остальных, эти вычисления можно производить параллельно.~\cite{book1}

Так как на этапе отбора, следующем за вычислением приспособленности, более приспособленные индивидуумы обычно считаются лучшими решениями, генетические алгоритмы естественно «заточены» под нахождение максимумов функции приспособленности. Если в какой-то задаче нужен минимум, то при вычислении приспособленности следует инвертировать найденное значение, например умножив его на $–1$.~\cite{book1}

Применение генетических операторов к популяции приводит к созданию новой популяции, основанной на лучших индивидуумах из текущей.~\cite{book1}

Оператор \textbf{отбора} отвечает за отбор индивидуумов из текущей популяции таким образом, что предпочтение отдаётся лучшим.~\cite{book1}

Оператор \textbf{скрещивания} (или рекомбинации) создаёт потомка выбранных индивидуумов. Обычно для этого берутся два индивидуума, и части их хромосом меняются местами, в результате чего создаются две новые хромосомы, представляющие двух потомков.~\cite{book1}

Оператор \textbf{мутации} вносит случайные изменения в один или несколько генов хромосомы вновь созданного индивидуума. Обычно вероятность мутации очень мала.~\cite{book1}

\section{Эволюционный алгоритм муравьиной кучи}

Идея \textbf{муравьиных алгоритмов оптимизации} (Ant Colony Optimization – ACO) подсказана способом поиска пищи некоторыми видами насекомых. Муравьи начинают рыскать случайным образом, и когда один находит пищу, он возвращается в муравейник, помечая свой путь феромонами. Другие муравьи, нашедшие пищу в том же месте, усиливают след, оставляя собственные феромоны. Со временем феромоновые метки выветриваются, поэтому более короткие пути и пути, по которым прошло больше муравьёв, имеют преимущество.~\cite{book1}

В муравьиных алгоритмах используются искусственные муравьи, которые обследуют пространство поиска, стремясь найти лучшие решения. Критерием отбора решений в случае аппроксимации функций является среднеквадратичное отклонение между аппроксимируемой и
аппроксимирующей функциями. Муравьи запоминают, где были и какие решения нашли по пути. Эта информация используется муравьями на следующих итерациях для поиска ещё лучших решений. Часто такие алгоритмы сочетаются с методами локального поиска, которые подключаются, когда найдена перспективная область.~\cite{book1}

Алгоритм оптимизации на основе муравьиной кучи (Dorigo, 1992) изначально был предложены для решения задач комбинаторной оптимизации (COP). Примеры COP включают планирование, маршрутизацию транспортных средств, составление расписания и т. д. С момента появления ACO как инструмента комбинаторной оптимизации предпринимались попытки использовать его для решения задач в непрерывных областях (continous domains). Однако применить метаэвристику ACO к непрерывным областям было непросто, и предлагаемые методы часто черпали вдохновение из ACO, но не следовали ему в точности.~\cite{book2}~\cite{article1}

Центральным компонентом алгоритмов ACO является модель феромонов, которая используется для вероятностной выборки пространства поиска. Его можно вывести из рассматриваемой модели COP. Модель COP можно определить следующим образом:~\cite{article1}

\begin{itemize}
	\item пространство поиска $S$, определённое над конечным набором дискретных переменных  и набором $\Omega$ ограничений среди переменных;
	\item целевая функция $f: S \longrightarrow \mathbb{R}_0^+$, значение которой должно быть минимизировано.
\end{itemize}

Модель COP используется для получения модели феромонов, используемой ACO. Подобно задаче комбинаторной оптимизации (COP), также может быть формально определена модель задачи непрерывной оптимизации (CnOP):~\cite{article1}

\begin{itemize}
	\item пространство поиска $S$, определённое над конечным набором непрерывных переменных  и набором $\Omega$ ограничений среди переменных;
	\item целевая функция $f: S \longrightarrow \mathbb{R}_0^+$, значение которой должно быть минимизировано.
\end{itemize}

В ACO для комбинаторной оптимизации информация о феромонах хранится в виде таблицы. На каждой итерации при выборе компонента, добавляемого к текущему частному решению, муравей использует некоторые значения из этой таблицы в качестве дискретного распределения вероятностей. В случае непрерывной оптимизации выбор, который делает муравей, не ограничивается конечным множеством. Следовательно, невозможно представить феромон в виде таблицы. Поэтому для непрерывной оптимизации используется следующая идея. Таблица феромонов обновляется на основе найденных компонентов хороших решений — так же, как и в обычном ACO. Однако в обычном ACO фактические решения, найденные муравьями, отбрасываются после обновления таблицы феромонов. Напротив, в данном случае необходимо отслеживать определённое количество решений, используемых для обновления таблицы феромонов. Вместо использования испарения феромонов феромон, связанный с самыми старыми решениями, в конечном итоге удаляется путём обновления таблицы феромонов, тем самым сводя на нет своё влияние.

Количество решений, сохранённых в архиве, установлено равным k, и поэтому этот параметр определяет сложность функции PDF (Probability Density Function --- функция плотности вероятности, чаще всего для распределения Гаусса). Далее на основе PDF формируется вектор весов решений, используемых для их отбора.

\section*{Вывод}

В данном разделе были описаны алгоритмы генетической и эволюционной оптимизации в контексте задачи аппроксимации функций.

\clearpage
